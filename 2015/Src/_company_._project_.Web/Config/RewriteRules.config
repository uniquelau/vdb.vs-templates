<?xml version="1.0" encoding="utf-8"?>
<rules>
  
  <rule name="Force HTTPS" stopProcessing="true">
    <match url="(.*)" ignoreCase="false" />
    <conditions>
      <add input="{HTTPS}" pattern="off" />
    </conditions>
    <action type="Redirect" url="https://{HTTP_HOST}/{R:1}" appendQueryString="true" redirectType="Permanent" />
  </rule>

  <!-- Redirect to WWW -->
  <!--
  <rule name="Redirect to WWW" stopProcessing="true">
    <match url="(.*)" />
    <conditions>
      <add input="{HTTP_HOST}" pattern="^www\." negate="true" />
      <add input="{HTTP_HOST}" pattern="(.+)azurewebsites.net" negate="true" />
    </conditions>
    <action type="Redirect" url="https://www.domain.com{REQUEST_URI}" redirectType="Permanent" appendQueryString="false" />
  </rule>
  -->

  <!-- Handle old URL's, see RewriteMaps.config -->
  <rule name="Redirect rule for Legacy URLS">
    <match url=".*" />
    <conditions>
      <add input="{Legacy URLS:{REQUEST_URI}}" pattern="(.+)" />
    </conditions>
    <action type="Redirect" url="{C:1}" appendQueryString="false" />
  </rule>

  <!-- Robots - Enable indexing on production domains -->
  <rule name="Rewrite Release robots.txt" stopProcessing="true">
    <match url="robots.txt" />
    <action type="Rewrite" url="/robots.Release.txt" />
    <conditions>
      <add input="{HTTP_HOST}" pattern="(.+)azurewebsites.net" negate="true" />
    </conditions>
  </rule>
  
  <!-- Robots - Blocks indexing of non production domains -->
  <rule name="Rewrite development robots.txt" stopProcessing="true">
    <match url="robots.txt" />
    <action type="Rewrite" url="/robots.txt" />
    <conditions>
      <add input="{HTTP_HOST}" pattern="(.+)azurewebsites.net" />
    </conditions>
  </rule>

</rules>
